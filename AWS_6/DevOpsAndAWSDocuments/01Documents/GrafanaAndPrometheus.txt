Kubernetes HA Set up  (Multi Node Cluster with kubeadm)
================================================

-> Create one security group with below inbound rules

		Rule-1 : "Type : SSH (22), Source : Anywhere"

		Rule-2 : "Type : ALL TCP , Source: Anywhere"

-> Create 3 virtual machines using Ubuntu 20.04 version AMI  by selecting above  created security group

		1 Master Node : t2.medium

		2 Worker Nodes :  t2.medium

********************************  Note: Use UBUNTU 20.04 version AMI for all 3 machines *************************************


================== Part-1 : Master & Worker Nodes Common Commands Execution start ====================


# Upgrade apt packages
$ sudo apt-get update

#Create configuration file for containerd:
$ cat <<EOF | sudo tee /etc/modules-load.d/containerd.conf overlay br_netfilter 
EOF

#Load modules:

$ sudo modprobe overlay
$ sudo modprobe br_netfilter


#Set system configurations for Kubernetes networking:

$ cat <<EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
net.bridge.bridge-nf-call-ip6tables = 1
EOF


#Apply new settings:
$ sudo sysctl --system

#Install containerd:

$ sudo apt-get update && sudo apt-get install -y containerd


# Create default configuration file for containerd:

$ sudo mkdir -p /etc/containerd


#Generate default containerd configuration and save to the newly created default file:

$ sudo containerd config default | sudo tee /etc/containerd/config.toml


#Restart containerd to ensure new configuration file usage:

$ sudo systemctl restart containerd


#Verify that containerd is running (optional)

$ sudo systemctl status containerd (presss ctrl+c for exit)


#Disable swap:

$ sudo swapoff -a


#Disable swap on startup in /etc/fstab:

$ sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab


#Install dependency packages:

$ sudo apt-get update && sudo apt-get install -y apt-transport-https curl


# Download and add GPG key:

$ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -


# Add Kubernetes to repository list:

$ cat <<EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF


Update package listings:

$ sudo apt-get update


# Install Kubernetes packages (Note: If you get a dpkg lock message, just wait a minute or two before trying the command again):

$ sudo apt-get install -y  kubelet kubeadm kubectl kubernetes-cni nfs-common


# Turn off automatic updates:

$ sudo apt-mark hold kubelet kubeadm kubectl kubernetes-cni nfs-common


=====================Common Commands Execution End=========================================


=================Part-2 : Only Master Node Commands Execution Start===================================


# Initialize the Cluster
$ sudo kubeadm init

# Set kubectl access:
$ mkdir -p $HOME/.kube
$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
$ sudo chown $(id -u):$(id -g) $HOME/.kube/config


# Test access to cluster:
$ kubectl get nodes


# Install the Calico Network Add-On -
# On the Control Plane Node, install Calico Networking:

$ kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
$ kubectl get nodes


# Join the Worker Nodes to the Cluster
$ kubeadm token create --print-join-command

Note : In both Worker Nodes, paste the kubeadm join command to join the cluster. Use sudo to run it as root:

$ sudo kubeadm join ...

In the Control Plane Node, view cluster status (Note: You may have to wait a few moments to allow all nodes to become ready):

#command to join other nodes as master


=====================================================
Validate the setup by executing below command in master-node
=====================================================
$  kubectl get nodes

===========================================================================================
*******************************************************************************************
					K8S HELM
*******************************************************************************************
===========================================================================================

-> We deployed our apps in Kubernetes cluster using Manifest files

-> Manifest files we can write in 2 ways

1) JSON
2) YML (more demand)

-> It is difficult to write manifest files for our applications

-> Helm is a package manager for k8s applications

-> Helm allows you to install or deploy applications on kubernetes cluster in a similar manner to yum/apt for linux distributions.

-> Helm lets you fetch, deploy and manage the lifecycle of applications both 3rd party apps and your own applications

Ex: prometheus, grafana, nginx-ingress, ELK stack are third party apps 


-> Helm introduces several familiar concepts such as 

Helm Chart (package contains k8s manifests - templates)

Helm Repositories which holds helm charts/packages

A CLI with install/upgrade/remove commands

================
Why to use Helm?
================

-> Deploying application on K8S cluster is little difficult 

-> As part of app deployment we need to create below k8s objects

Deployment
Service
ConfigMaps/Secrets
Volumes
Ingress Rules
HPA

-> Helm greatly simplifies the process of creating, deploying and managing applications on k8s cluster 

-> Heml also maintains a versioned history of very chart (application) installation. If something goes wrong , you can simply call 'helm rollback'.


-> Setting up a single application can involve creating multiple independent k8s resources and each resource requires a manifest file.


####################
What is Helm Chart
####################

-> HELM chart is a basically just a collection of manifest files organized in a specific directory structure that describe a related K8S resource.

-> There are two main components in HELM chart

1) template 
2) value

-> Templates and values renders a manifest which can understand by k8s 


-> Helm uses charts to pack all the required k8s components (manifests) for an application to deploy, run and scale.

-> charts are very similar to RPM and DEB packages for Linux.

Ex: yum install git

Note: it will interact with repo and it will download git 

 
##############
HELM Concepts
##############

-> Helm packages are called charts, and they consist of a few YML configuration files and some templates that are rendered into K8S manifest files. Here is the basic directory structure of a chart.

charts : dependent charts will be added here

templates: contains all template files

values : It contains values which are required for templates


##################
Helm Installation
##################

$ curl -fsSl -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3

$ chmod 700 get_helm.sh

$ ./get_helm.sh

$ helm

-> check do we have metrics server on the cluster

$ kubectl top pods

$ kubectl top nodes

# check helm repos 
$ helm repo ls

# Before you can install the chart you will need to add the metrics-server repo to helm
$ helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server/

# Install the chart
$ helm upgrade --install metrics-server metrics-server/metrics-server

$ helm list

$ helm delete <release-name>



================================
Metric Server Unavailability issue fix
================================
URL : https://www.linuxsysadmins.com/service-unavailable-kubernetes-metrics/

# Apply Metric server
$ kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.4.1/components.yaml


# Edit metrics-server and update properties
$ kubectl edit deployments.apps -n kube-system metrics-server 

=> Edit the below file and add  new properties which are given below

--------------------------- Existing File--------------------
 spec:
      containers:
      - args:
        - --cert-dir=/tmp
        - --secure-port=4443

--------------------------- New File--------------------
---
    spec:
      containers:
      - args:
        - --cert-dir=/tmp
        - --secure-port=4443
        - --kubelet-insecure-tls=true
        - --kubelet-preferred-address-types=InternalIP

------------------------------------------------------------------

$ kubectl top pods

$ kubectl top nodes

===========================================================================================
*******************************************************************************************
					Kubernetes Monitoring
*******************************************************************************************
===========================================================================================
=> We can monitor our k8s cluster and cluster components using below softwares

1) Prometheus
2) Grafana

=============
Prometheus
=============

-> Prometheus is an open-source systems monitoring and alerting toolkit

-> Prometheus collects and stores its metrics as time series data

-> It provides better monitoring capabilities for the k8s container orchestration platform.


=============
Grafana
=============

-> Grafana is a  analysis and monitoring tool

-> Grafana is a multi-platform open source analytics and interactive visualization web application.

-> It provides charts, graphs, and alerts for the web when connected to supported data sources.

-> Grafana allows you to query, visualize, alert on and understand your metrics no matter where they are stored. Create, explore and share dashboards.


Note: Graphana will connect with Prometheus for data source.


#########################################
How to deploy Grafana & Prometheus in K8S
##########################################

-> Using HELM charts we can easily deploy Prometheus and Grafana


##################################################
Install Prometheus & Grafana In K8S Cluster using HELM
#################################################

# Add the latest helm repository in Kubernetes
$ helm repo add stable https://charts.helm.sh/stable

# Add prometheus repo to helm
$ helm repo add prometheus-community https://prometheus-community.github.io/helm-charts

# Update Helm Repo
$ helm repo update

# Search Repo
$ helm search repo prometheus-community

# install prometheus
$ helm install stable prometheus-community/kube-prometheus-stack

# Get all pods 
$ kubectl get pods

Node: You should see prometheus pods running

# Check the services 
$ kubectl get svc

# By default prometheus and grafana services are available within the cluster as ClusterIP, to access them outside lets change it to NodePort.

# Edit Prometheus Service & change service type to NodePort then save and close that file
$ kubectl edit svc stable-kube-prometheus-sta-prometheus

# Now edit the grafana service & change service type to NodePort then save and close that file
$ kubectl edit svc stable-grafana


# Verify the service if changed to LoadBalancer
$ kubectl get svc

# Check in which nodes our Prometheus and grafana pods are running
$ kubectl get pods -o wide

=> Access Promethues server using below URL

		URL : http://node-ip:nodeport/

=> Access Grafana server using below URL

		URL : http://node-ip:nodeport/

=> Use below credentials to login into grafana server

UserName: admin
Password: prom-operator

=> Once we login into Grafana then we can monitor our k8s cluster. Grafana will provide all the data in charts format.











